{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Sim RL Training\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Environment\n",
    "from osim.env import L2RunEnv as ENV # rename environment to be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.processors import WhiteningNormalizerProcessor\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class\n",
    "Reference: https://github.com/keras-rl/keras-rl/blob/master/examples/ddpg_mujoco.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,env):\n",
    "        nb_actions = env.action_space.shape[0]\n",
    "        \n",
    "        self.env = env\n",
    "        self.actor = self.build_actor(env)\n",
    "        self.critic, action_input = self.build_critic(env)\n",
    "        self.loss = self.build_loss()\n",
    "\n",
    "        self.memory = SequentialMemory(limit=100000, window_length=1)\n",
    "        self.random_process = OrnsteinUhlenbeckProcess(size=nb_actions, theta=.15, mu=0., sigma=.1)\n",
    "        self.agent = DDPGAgent(   nb_actions=nb_actions, actor=self.actor, \n",
    "                                  critic=self.critic, critic_action_input=action_input,\n",
    "                                  memory=self.memory, nb_steps_warmup_critic=1000, \n",
    "                                  nb_steps_warmup_actor=1000,\n",
    "                                  random_process=self.random_process, \n",
    "                                  gamma=.99, target_model_update=1e-3,\n",
    "                                  processor=WhiteningNormalizerProcessor()  )\n",
    "        self.agent.compile([Adam(lr=1e-4), Adam(lr=1e-3)], metrics=self.loss)\n",
    "\n",
    "    def build_loss(self):\n",
    "        return ['mse']\n",
    "\n",
    "    def build_actor(self,env):\n",
    "        nb_actions = env.action_space.shape[0]\n",
    "        actor = Sequential()\n",
    "        actor.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "        actor.add(Dense(400))\n",
    "        actor.add(Activation('relu'))\n",
    "        actor.add(Dense(300))\n",
    "        actor.add(Activation('relu'))\n",
    "        actor.add(Dense(nb_actions,\n",
    "                        activation='tanh',\n",
    "                        kernel_constraint=  keras.constraints.min_max_norm(\n",
    "                                            min_value=0,\n",
    "                                            max_value=nb_actions,\n",
    "                                            axis=1) ) )\n",
    "        actor.summary()\n",
    "\n",
    "        inD = Input(shape=(1,) + env.observation_space.shape)\n",
    "        out = actor(inD)\n",
    "\n",
    "        return Model(inD,out)\n",
    "\n",
    "    def build_critic(self,env):\n",
    "        nb_actions = env.action_space.shape[0]\n",
    "        action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "        observation_input = Input(shape=(1,) + env.observation_space.shape, name='observation_input')\n",
    "        flattened_observation = Flatten()(observation_input)\n",
    "        x = Dense(400)(flattened_observation)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Concatenate()([x, action_input])\n",
    "        x = Dense(300)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation('linear')(x)\n",
    "\n",
    "        critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "        critic.summary()\n",
    "\n",
    "        return critic, action_input\n",
    "    \n",
    "    def fit(self, **kwargs):\n",
    "        return self.agent.fit(self.env,**kwargs)\n",
    "    \n",
    "    def test(self, **kwargs):\n",
    "        return self.agent.test(self.env,**kwargs)\n",
    "    \n",
    "    def save_weights(self,filename='ddpg_{}_weights.h5f'):\n",
    "        self.agent.save_weights(filename.format(\"opensim\"), overwrite=True)\n",
    "        \n",
    "    def load_weights(self,filename='ddpg_{}_weights.h5f'):\n",
    "        self.agent.load_weights(filename.format(\"opensim\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrainEnv(ENV):\n",
    "    pass\n",
    "# TODO: define virtual assistant forces on agent\n",
    "# TODO: define search through easier environments\n",
    "# TODO: make environment harder once the agent has trained for challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulation\n",
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quinn/gym/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "env = TrainEnv(visualize=True)\n",
    "observation = env.reset( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 41)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               16800     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                5418      \n",
      "=================================================================\n",
      "Total params: 142,518\n",
      "Trainable params: 142,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observation_input (InputLayer)  (None, 1, 41)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 41)           0           observation_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 400)          16800       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 400)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "action_input (InputLayer)       (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 418)          0           activation_3[0][0]               \n",
      "                                                                 action_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          125700      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 300)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            301         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1)            0           dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 142,801\n",
      "Trainable params: 142,801\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previously trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.load_weights( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train new weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0): # Train in smaller batches to allow for interuption\n",
    "    print(\"\\n\\niteration:\",i)\n",
    "    agent.fit(nb_steps=2000, visualize=False, verbose=2)\n",
    "    ## Always save new weights\n",
    "    agent.save_weights( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 0.468, steps: 85\n",
      "Episode 2: reward: 0.459, steps: 88\n",
      "Episode 3: reward: 0.469, steps: 88\n",
      "Episode 4: reward: 0.468, steps: 88\n",
      "Episode 5: reward: 0.473, steps: 88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1aa58b38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(nb_episodes=5, visualize=True, nb_max_episode_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
